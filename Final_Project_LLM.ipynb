{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/balakrishna-24/ppt-generator/blob/main/Final_Project_LLM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V1w8Fm5wZM11",
        "outputId": "dda74bd8-f4b3-4e9c-f90b-32b609eb8e5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.8/91.8 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.9/210.9 kB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m990.6/990.6 kB\u001b[0m \u001b[31m65.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m360.7/360.7 kB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.5/61.5 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.5/52.5 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.5/109.5 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.0/138.0 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m774.0/774.0 kB\u001b[0m \u001b[31m34.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.0/233.0 kB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m525.5/525.5 kB\u001b[0m \u001b[31m45.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m83.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.8/207.8 kB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.6/131.6 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m327.6/327.6 kB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m76.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m384.0/384.0 kB\u001b[0m \u001b[31m35.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.2/48.2 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.2/140.2 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.8/295.8 kB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.1/71.1 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m67.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m273.8/273.8 kB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.2/139.2 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.1/93.1 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m104.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m80.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m204.3/204.3 kB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m113.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m110.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m254.1/254.1 kB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.5/12.5 MB\u001b[0m \u001b[31m114.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m97.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m32.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.7/82.7 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m106.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m427.7/427.7 kB\u001b[0m \u001b[31m37.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-metadata 1.15.0 requires protobuf<4.21,>=3.20.3; python_version < \"3.11\", but you have protobuf 4.25.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.2/84.2 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.1/115.1 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.6/21.6 MB\u001b[0m \u001b[31m85.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.8/341.8 kB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.4/9.4 MB\u001b[0m \u001b[31m120.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m476.0/476.0 kB\u001b[0m \u001b[31m40.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.7/98.7 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for docx2txt (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!pip install crewai -qqq\n",
        "\n",
        "!pip install 'crewai[tools]' -qqq"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fhpWRMazZhxg"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vAWl3n8bZk57",
        "outputId": "1a1bdd7f-d9ce-4966-ebc3-224ea5b96c88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.40.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.4.2)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.7.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.20.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gzWfdKv_Zoha"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "OPENAI_API_KEY=userdata.get('openai-key')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "blO05qJkZqkH"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import openai\n",
        "import pandas as pd\n",
        "os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kEM6WDroZsvu"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "llm_executor=ChatOpenAI(\n",
        "    model=\"gpt-4\",\n",
        "    temperature=0\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OdCjFp40Zw5U",
        "outputId": "ee7287ac-c9fe-4779-9996-2a3611250006"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.26.4)\n",
            "Collecting yt-dlp\n",
            "  Downloading yt_dlp-2024.8.6-py3-none-any.whl.metadata (170 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m170.1/170.1 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting brotli (from yt-dlp)\n",
            "  Downloading Brotli-1.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from yt-dlp) (2024.7.4)\n",
            "Collecting mutagen (from yt-dlp)\n",
            "  Downloading mutagen-1.47.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting pycryptodomex (from yt-dlp)\n",
            "  Downloading pycryptodomex-3.20.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: requests<3,>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from yt-dlp) (2.32.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.26.17 in /usr/local/lib/python3.10/dist-packages (from yt-dlp) (2.0.7)\n",
            "Requirement already satisfied: websockets>=12.0 in /usr/local/lib/python3.10/dist-packages (from yt-dlp) (12.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.32.2->yt-dlp) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.32.2->yt-dlp) (3.7)\n",
            "Downloading yt_dlp-2024.8.6-py3-none-any.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m86.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Brotli-1.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m105.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mutagen-1.47.0-py3-none-any.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.4/194.4 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pycryptodomex-3.20.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m87.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: brotli, pycryptodomex, mutagen, yt-dlp\n",
            "Successfully installed brotli-1.1.0 mutagen-1.47.0 pycryptodomex-3.20.0 yt-dlp-2024.8.6\n",
            "Collecting python-pptx\n",
            "  Downloading python_pptx-1.0.2-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: Pillow>=3.3.2 in /usr/local/lib/python3.10/dist-packages (from python-pptx) (9.4.0)\n",
            "Collecting XlsxWriter>=0.5.7 (from python-pptx)\n",
            "  Downloading XlsxWriter-3.2.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from python-pptx) (4.9.4)\n",
            "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.10/dist-packages (from python-pptx) (4.12.2)\n",
            "Downloading python_pptx-1.0.2-py3-none-any.whl (472 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m472.8/472.8 kB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading XlsxWriter-3.2.0-py3-none-any.whl (159 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m159.9/159.9 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: XlsxWriter, python-pptx\n",
            "Successfully installed XlsxWriter-3.2.0 python-pptx-1.0.2\n",
            "Collecting pytesseract\n",
            "  Downloading pytesseract-0.3.10-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (24.1)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (9.4.0)\n",
            "Downloading pytesseract-0.3.10-py3-none-any.whl (14 kB)\n",
            "Installing collected packages: pytesseract\n",
            "Successfully installed pytesseract-0.3.10\n",
            "Requirement already satisfied: pytube in /usr/local/lib/python3.10/dist-packages (15.0.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.26.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install opencv-python\n",
        "\n",
        "!pip install yt-dlp\n",
        "\n",
        "!pip install python-pptx\n",
        "!pip install pytesseract\n",
        "!pip install pytube opencv-python\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aaFTKeCcZzGm",
        "outputId": "2fa34e99-34f4-41ac-aa46-137b8bed4eeb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain-openai in /usr/local/lib/python3.10/dist-packages (0.1.20)\n",
            "Requirement already satisfied: langchain-core<0.3.0,>=0.2.26 in /usr/local/lib/python3.10/dist-packages (from langchain-openai) (0.2.29)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.32.0 in /usr/local/lib/python3.10/dist-packages (from langchain-openai) (1.40.2)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.10/dist-packages (from langchain-openai) (0.7.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.26->langchain-openai) (6.0.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.26->langchain-openai) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.75 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.26->langchain-openai) (0.1.98)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.26->langchain-openai) (24.1)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.26->langchain-openai) (2.8.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.26->langchain-openai) (8.5.0)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.26->langchain-openai) (4.12.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.32.0->langchain-openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.32.0->langchain-openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.32.0->langchain-openai) (0.27.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.32.0->langchain-openai) (0.4.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.32.0->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.32.0->langchain-openai) (4.66.5)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2023.12.25)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2.32.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.32.0->langchain-openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.32.0->langchain-openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.32.0->langchain-openai) (2024.7.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.32.0->langchain-openai) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.32.0->langchain-openai) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.26->langchain-openai) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3.0,>=0.2.26->langchain-openai) (3.10.7)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.3.0,>=0.2.26->langchain-openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.3.0,>=0.2.26->langchain-openai) (2.20.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (2.0.7)\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain-openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WAZY_jzOZ2Zx",
        "outputId": "384fa487-6a8a-4806-de9e-ab859961b926"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Database and table created successfully.\n"
          ]
        }
      ],
      "source": [
        "import sqlite3\n",
        "\n",
        "# Connect to the database (or create it)\n",
        "conn = sqlite3.connect('images.db')\n",
        "c = conn.cursor()\n",
        "\n",
        "# Create table to store images\n",
        "c.execute('''\n",
        "    CREATE TABLE IF NOT EXISTS images (\n",
        "        id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "        filename TEXT,\n",
        "        image BLOB\n",
        "    )\n",
        "''')\n",
        "\n",
        "conn.commit()\n",
        "conn.close()\n",
        "\n",
        "print(\"Database and table created successfully.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get update\n",
        "!sudo apt-get install ffmpeg\n",
        "\n",
        "!yt-dlp -vU\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_GVZkbKMfmbQ",
        "outputId": "51a1e1fc-bb73-4365-ac33-3d86c41f8470"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "\r0% [Connecting to archive.ubuntu.com (91.189.91.83)] [Connecting to security.ub\r0% [Connecting to archive.ubuntu.com (91.189.91.83)] [Connecting to security.ub\r                                                                               \rGet:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [921 kB]\n",
            "Get:4 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Ign:7 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:8 https://r2u.stat.illinois.edu/ubuntu jammy Release\n",
            "Get:9 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,152 kB]\n",
            "Hit:11 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:12 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:13 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:14 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,441 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [2,841 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [2,954 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,422 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy-updates/multiverse amd64 Packages [51.8 kB]\n",
            "Fetched 13.0 MB in 3s (3,905 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 45 not upgraded.\n",
            "[debug] Command-line config: ['-vU']\n",
            "[debug] Encodings: locale UTF-8, fs utf-8, pref UTF-8, out utf-8, error utf-8, screen utf-8\n",
            "[debug] yt-dlp version stable@2024.08.06 from yt-dlp/yt-dlp [4d9231208] (pip)\n",
            "[debug] Python 3.10.12 (CPython x86_64 64bit) - Linux-6.1.85+-x86_64-with-glibc2.35 (OpenSSL 3.0.2 15 Mar 2022, glibc 2.35)\n",
            "[debug] exe versions: ffmpeg 4.4.2 (setts), ffprobe 4.4.2\n",
            "[debug] Optional libraries: Cryptodome-3.20.0, brotli-1.1.0, certifi-2024.07.04, mutagen-1.47.0, requests-2.32.3, secretstorage-3.3.1, sqlite3-3.37.2, urllib3-2.0.7, websockets-12.0\n",
            "[debug] Proxy map: {'colab_language_server': '/usr/colab/bin/language_service'}\n",
            "[debug] Request Handlers: urllib, requests, websockets\n",
            "[debug] Loaded 1830 extractors\n",
            "[debug] Fetching release info: https://api.github.com/repos/yt-dlp/yt-dlp/releases/latest\n",
            "Latest version: stable@2024.08.06 from yt-dlp/yt-dlp\n",
            "yt-dlp is up to date (stable@2024.08.06 from yt-dlp/yt-dlp)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!yt-dlp -U\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_nOewxEXTCfU",
        "outputId": "35ae08b9-df9a-4404-da9d-31107710ffc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Latest version: stable@2024.08.06 from yt-dlp/yt-dlp\n",
            "yt-dlp is up to date (stable@2024.08.06 from yt-dlp/yt-dlp)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BQMsg3qkZ4hc"
      },
      "outputs": [],
      "source": [
        "import sqlite3\n",
        "import cv2\n",
        "from yt_dlp import YoutubeDL\n",
        "import hashlib\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "from typing import List\n",
        "from crewai_tools import tool\n",
        "\n",
        "# Function to download YouTube video\n",
        "def download_youtube_video(url: str) -> str:\n",
        "    \"\"\"Download a YouTube video using yt-dlp.\"\"\"\n",
        "    url_hash = hashlib.md5(url.encode()).hexdigest()\n",
        "    output_path = f'video_{url_hash}.mp4'\n",
        "\n",
        "    ydl_opts = {\n",
        "        'format': 'best',\n",
        "        'outtmpl': output_path,\n",
        "    }\n",
        "    try:\n",
        "        with YoutubeDL(ydl_opts) as ydl:\n",
        "            ydl.download([url])\n",
        "        print(f\"Downloaded video to {output_path}\")\n",
        "        return output_path\n",
        "    except Exception as e:\n",
        "        print(f\"Error downloading video: {e}\")\n",
        "        return None\n",
        "\n",
        "# Function to clear the database\n",
        "def clear_database():\n",
        "    conn = sqlite3.connect('images.db')\n",
        "    c = conn.cursor()\n",
        "    c.execute('DELETE FROM images')\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "# Function to insert an image into the database\n",
        "def insert_image_into_db(filename: str, image: bytes):\n",
        "    conn = sqlite3.connect('images.db')\n",
        "    c = conn.cursor()\n",
        "    c.execute(\"INSERT INTO images (filename, image) VALUES (?, ?)\", (filename, image))\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "# Function to get frames from a video with FPS control\n",
        "def get_frames(video_path: str, fps: int):\n",
        "    vs = cv2.VideoCapture(video_path)\n",
        "    if not vs.isOpened():\n",
        "        raise Exception(f'Unable to open file {video_path}')\n",
        "\n",
        "    video_fps = vs.get(cv2.CAP_PROP_FPS)  # Get the original frame rate of the video\n",
        "    frame_interval = int(video_fps // fps)  # Calculate the interval based on desired fps\n",
        "\n",
        "    frame_count = 0\n",
        "    while True:\n",
        "        success, frame = vs.read()\n",
        "        if not success:\n",
        "            break\n",
        "        if frame_count % frame_interval == 0:\n",
        "            yield frame\n",
        "        frame_count += 1\n",
        "    vs.release()\n",
        "\n",
        "# Function to detect unique screenshots\n",
        "def detect_unique_screenshots(video_path: str, fps: int):\n",
        "    screenshots_count = 0\n",
        "    for frame in get_frames(video_path, fps):\n",
        "        screenshots_count += 1\n",
        "        _, img_encoded = cv2.imencode('.png', frame)\n",
        "        insert_image_into_db(f\"screenshot_{screenshots_count}.png\", img_encoded.tobytes())\n",
        "    print(f'{screenshots_count} screenshots Captured!')\n",
        "\n",
        "# Function to fetch images from the database\n",
        "def fetch_images_from_db():\n",
        "    conn = sqlite3.connect('images.db')\n",
        "    c = conn.cursor()\n",
        "    c.execute(\"SELECT id, filename, image FROM images\")\n",
        "    images = c.fetchall()\n",
        "    conn.close()\n",
        "    return images\n",
        "\n",
        "# Function to display remaining images\n",
        "def display_remaining_images():\n",
        "    remaining_images = fetch_images_from_db()\n",
        "    for id, filename, image_data in remaining_images:\n",
        "        np_image = np.frombuffer(image_data, dtype=np.uint8)\n",
        "        img = cv2.imdecode(np_image, cv2.IMREAD_COLOR)\n",
        "        cv2_imshow(img)\n",
        "        print(f\"Displayed {filename}\")\n",
        "\n",
        "# Tool for processing YouTube videos\n",
        "@tool\n",
        "def youtube_video_processing_tool(video_urls: List[str], fps: int = 30, threshold: float = 0.4) -> str:\n",
        "    \"\"\"\n",
        "    This tool processes YouTube videos to extract unique frames, store them, and remove duplicates.\n",
        "\n",
        "    Args:\n",
        "    - video_urls (List[str]): List of YouTube video URLs to process.\n",
        "    - fps (int): Desired frames per second to capture.\n",
        "    - threshold (float): Similarity threshold to identify duplicate frames.\n",
        "\n",
        "    Returns:\n",
        "    - str: A confirmation message that the processing is complete.\n",
        "    \"\"\"\n",
        "    for video_url in video_urls:\n",
        "        video_path = download_youtube_video(video_url)\n",
        "        if video_path:\n",
        "            clear_database()\n",
        "            detect_unique_screenshots(video_path, fps)\n",
        "            print(f\"Processing complete. Frames captured.\")\n",
        "    display_remaining_images()\n",
        "    return \"Processing complete.\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HIxf2bcrZ7Ct"
      },
      "outputs": [],
      "source": [
        "from crewai import Agent, Task, Crew, Process\n",
        "from crewai_tools import Tool\n",
        "\n",
        "video_processor_agent = Agent(\n",
        "    role='Video Processor',\n",
        "    goal='Process YouTube videos to extract and manage unique frames',\n",
        "    verbose=True,\n",
        "    memory=True,\n",
        "    backstory=(\n",
        "        \"You are a diligent video processing expert with a knack for extracting and managing unique frames from YouTube videos.you are good at analysing the images and you always take clear images where text is clearly visible and will take of the images \"\n",
        "\n",
        "    ),\n",
        "\n",
        "    tools=[youtube_video_processing_tool]\n",
        "\n",
        ")\n",
        "\n",
        "# Define the task\n",
        "video_processing_task = Task(\n",
        "    description=(\n",
        "        \"Given a  YouTube {video_urls},need to download and  process video to extract unique frames, \"\n",
        "        \"store them in a database \"\n",
        "        \"Your final output should display the remaining unique frames.\"\n",
        "        \"you need to take threshold value as 0.96 and the interval as 5\"\n",
        "        \"you need to take a clear image no blurr image and the text in evry image should be clearly visible and if there is any unckear text image dont display that images and delete that image from the database\"\n",
        "    ),\n",
        "    expected_output='A confirmation message that the processing is complete along with displayed images.',\n",
        "    tools=[youtube_video_processing_tool],\n",
        "    agent=video_processor_agent\n",
        ")\n",
        "video_processing_crew = Crew(\n",
        "    agents=[video_processor_agent],\n",
        "    tasks=[video_processing_task],\n",
        "    process=Process.sequential  # or Process.parallel based on your needs\n",
        ")\n",
        "\n",
        "# Inputs for the task\n",
        "\n",
        "\n",
        "# Kickoff the crew\n",
        "result = video_processing_crew.kickoff(inputs={\n",
        "    'video_urls': [\n",
        "        'https://www.youtube.com/watch?v=3BcO2USvA3k'\n",
        "    ],\n",
        "    'interval': 3,\n",
        "    'threshold': 0.4\n",
        "})\n",
        "print(result)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W2ZXB0EVaH94"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "ppt tool and agent !**bold text**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k9PRAVxNaMoY"
      },
      "outputs": [],
      "source": [
        "from crewai_tools import BaseTool, tool\n",
        "import sqlite3\n",
        "import numpy as np\n",
        "import cv2\n",
        "from pptx import Presentation\n",
        "from pptx.util import Inches\n",
        "from io import BytesIO\n",
        "from typing import List\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "def fetch_images_from_db():\n",
        "    '''Fetch images from the database'''\n",
        "    conn = sqlite3.connect('images.db')\n",
        "    c = conn.cursor()\n",
        "    c.execute(\"SELECT id, filename, image FROM images\")\n",
        "    images = c.fetchall()\n",
        "    conn.close()\n",
        "    return images\n",
        "\n",
        "def create_ppt(images: List[tuple]) -> Presentation:\n",
        "    '''Create a PowerPoint presentation with each image filling a slide'''\n",
        "    prs = Presentation()\n",
        "    for id, filename, image_data in images:\n",
        "        np_image = np.frombuffer(image_data, dtype=np.uint8)\n",
        "        img = cv2.imdecode(np_image, cv2.IMREAD_COLOR)\n",
        "\n",
        "        # Convert the OpenCV image (numpy array) to a format that can be added to PPT\n",
        "        image_stream = BytesIO()\n",
        "        success, encoded_image = cv2.imencode('.png', img)\n",
        "        image_stream.write(encoded_image.tobytes())\n",
        "        image_stream.seek(0)\n",
        "\n",
        "        slide = prs.slides.add_slide(prs.slide_layouts[6])  # Adding a blank slide layout\n",
        "\n",
        "        # Calculate the size and position to make the image fill the slide\n",
        "        img_width, img_height = img.shape[1], img.shape[0]\n",
        "        slide_width = prs.slide_width\n",
        "        slide_height = prs.slide_height\n",
        "        ratio = min(slide_width / img_width, slide_height / img_height)\n",
        "        pic_width = int(img_width * ratio)\n",
        "        pic_height = int(img_height * ratio)\n",
        "        pic_left = int((slide_width - pic_width) / 2)\n",
        "        pic_top = int((slide_height - pic_height) / 2)\n",
        "\n",
        "        slide.shapes.add_picture(image_stream, pic_left, pic_top, width=pic_width, height=pic_height)\n",
        "\n",
        "    return prs\n",
        "\n",
        "@tool\n",
        "def ppt_generator_tool() -> str:\n",
        "    \"\"\"\n",
        "    This tool generates a PowerPoint presentation from images stored in the database.\n",
        "\n",
        "    Returns:\n",
        "    - str: The path to the saved PowerPoint presentation.\n",
        "    \"\"\"\n",
        "    images = fetch_images_from_db()\n",
        "    print(f\"Remaining images in database: {len(images)}\")\n",
        "    prs = create_ppt(images)\n",
        "    ppt_path = '/content/presentation.pptx'\n",
        "    prs.save(ppt_path)\n",
        "    print(f\"PowerPoint saved at {ppt_path}\")\n",
        "    return ppt_path\n",
        "\n",
        "# # Example usage (in a real application, the tool would be called by an agent or task)\n",
        "# if __name__ == \"__main__\":\n",
        "#     ppt_path = ppt_generator_tool()\n",
        "#     print(f\"Generated PowerPoint presentation at: {ppt_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6gYvDxBLacUy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98ed1c93-8576-4582-b9eb-f923d54d5ab9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:opentelemetry.trace:Overriding of current TracerProvider is not allowed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new CrewAgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mI need to generate a PowerPoint presentation from the images stored in the database. To do this, I will use the `ppt_generator_tool` to create the presentation.\n",
            "\n",
            "Action: ppt_generator_tool\n",
            "Action Input: {}\u001b[0mRemaining images in database: 0\n",
            "PowerPoint saved at /content/presentation.pptx\n",
            "\u001b[95m \n",
            "\n",
            "/content/presentation.pptx\n",
            "\u001b[00m\n",
            "\u001b[32;1m\u001b[1;3mThought: I now know the final answer.\n",
            "\n",
            "Final Answer: /content/presentation.pptx\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "/content/presentation.pptx\n"
          ]
        }
      ],
      "source": [
        "from crewai import Agent, Task, Crew, Process\n",
        "\n",
        "# Define the agent with the ppt_generator_tool\n",
        "ppt_generator_agent = Agent(\n",
        "    role='PPT Generator',\n",
        "    goal='Generate a PowerPoint presentation from images stored in the database',\n",
        "    verbose=True,\n",
        "    memory=True,\n",
        "    backstory=(\n",
        "        \"You are an expert in creating compelling PowerPoint presentations. \"\n",
        "        \"You excel at transforming image data into well-organized slides.\"\n",
        "    ),\n",
        "    tools=[ppt_generator_tool]\n",
        ")\n",
        "\n",
        "# Define the task for generating the PowerPoint\n",
        "ppt_generation_task = Task(\n",
        "    description=(\n",
        "        \"Generate a PowerPoint presentation from the images stored in the database. \"\n",
        "        \"Each image should be placed on a separate slide, filling the slide.\"\n",
        "    ),\n",
        "    expected_output='A path to the saved PowerPoint presentation.',\n",
        "    agent=ppt_generator_agent,\n",
        ")\n",
        "\n",
        "# Create the crew with the agent and task\n",
        "ppt_generation_crew = Crew(\n",
        "    agents=[ppt_generator_agent],\n",
        "    tasks=[ppt_generation_task],\n",
        "    process=Process.sequential\n",
        ")\n",
        "\n",
        "# Kickoff the crew\n",
        "result = ppt_generation_crew.kickoff()\n",
        "print(result)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " **NON AGENTIC APPROACH**"
      ],
      "metadata": {
        "id": "1CCgq08zUCuu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install Pillow\n",
        "!pip install opencv-python\n",
        "\n",
        "!pip install yt-dlp\n",
        "\n",
        "!pip install python-pptx\n",
        "!pip install pytesseract\n",
        "!pip install pytube opencv-python\n"
      ],
      "metadata": {
        "id": "lgspVCqT9GJ1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f95929cf-37c9-4918-cbdc-5502a2e3c44f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (9.4.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.26.4)\n",
            "Requirement already satisfied: yt-dlp in /usr/local/lib/python3.10/dist-packages (2024.8.6)\n",
            "Requirement already satisfied: brotli in /usr/local/lib/python3.10/dist-packages (from yt-dlp) (1.1.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from yt-dlp) (2024.7.4)\n",
            "Requirement already satisfied: mutagen in /usr/local/lib/python3.10/dist-packages (from yt-dlp) (1.47.0)\n",
            "Requirement already satisfied: pycryptodomex in /usr/local/lib/python3.10/dist-packages (from yt-dlp) (3.20.0)\n",
            "Requirement already satisfied: requests<3,>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from yt-dlp) (2.32.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.26.17 in /usr/local/lib/python3.10/dist-packages (from yt-dlp) (2.0.7)\n",
            "Requirement already satisfied: websockets>=12.0 in /usr/local/lib/python3.10/dist-packages (from yt-dlp) (12.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.32.2->yt-dlp) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.32.2->yt-dlp) (3.7)\n",
            "Requirement already satisfied: python-pptx in /usr/local/lib/python3.10/dist-packages (1.0.2)\n",
            "Requirement already satisfied: Pillow>=3.3.2 in /usr/local/lib/python3.10/dist-packages (from python-pptx) (9.4.0)\n",
            "Requirement already satisfied: XlsxWriter>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from python-pptx) (3.2.0)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from python-pptx) (4.9.4)\n",
            "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.10/dist-packages (from python-pptx) (4.12.2)\n",
            "Requirement already satisfied: pytesseract in /usr/local/lib/python3.10/dist-packages (0.3.10)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (24.1)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (9.4.0)\n",
            "Requirement already satisfied: pytube in /usr/local/lib/python3.10/dist-packages (15.0.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.26.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "\n",
        "# Connect to the database (or create it)\n",
        "conn = sqlite3.connect('images.db')\n",
        "c = conn.cursor()\n",
        "\n",
        "# Create table to store images\n",
        "c.execute('''\n",
        "    CREATE TABLE IF NOT EXISTS images (\n",
        "        id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "        filename TEXT,\n",
        "        image BLOB\n",
        "    )\n",
        "''')\n",
        "\n",
        "conn.commit()\n",
        "conn.close()\n",
        "\n",
        "print(\"Database and table created successfully.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AHCOc4OjU2hT",
        "outputId": "12b1a755-3a79-4ddf-e9fd-43c7cf572fd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Database and table created successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import cv2\n",
        "import imutils\n",
        "from yt_dlp import YoutubeDL\n",
        "from google.colab.patches import cv2_imshow\n",
        "import sqlite3\n",
        "import hashlib\n",
        "\n",
        "############# Define constants\n",
        "\n",
        "FRAME_RATE = 3                   # no.of frames per second that needs to be processed, fewer the count faster the speed\n",
        "WARMUP = FRAME_RATE              # initial number of frames to be skipped\n",
        "FGBG_HISTORY = FRAME_RATE * 15   # no.of frames in background object\n",
        "VAR_THRESHOLD = 16               # Threshold on the squared Mahalanobis distance between the pixel and the model to decide whether a pixel is well described by the background model.\n",
        "DETECT_SHADOWS = False           # If true, the algorithm will detect shadows and mark them.\n",
        "MIN_PERCENT = 0.1                # min % of diff between foreground and background to detect if motion has stopped\n",
        "MAX_PERCENT = 3                  # max % of diff between foreground and background to detect if frame is still in motion\n",
        "\n",
        "def download_youtube_video(url):\n",
        "    \"\"\"Download a YouTube video using yt-dlp.\"\"\"\n",
        "    # Generate a unique filename based on the URL\n",
        "    url_hash = hashlib.md5(url.encode()).hexdigest()\n",
        "    output_path = f'video_{url_hash}.mp4'\n",
        "\n",
        "    ydl_opts = {\n",
        "        'format': 'best',\n",
        "        'outtmpl': output_path,\n",
        "    }\n",
        "    try:\n",
        "        with YoutubeDL(ydl_opts) as ydl:\n",
        "            ydl.download([url])\n",
        "        print(f\"Downloaded video to {output_path}\")\n",
        "        return output_path\n",
        "    except Exception as e:\n",
        "        print(f\"Error downloading video: {e}\")\n",
        "        return None\n",
        "\n",
        "def get_frames(video_path):\n",
        "    '''Return the frames from a video located at video_path, skipping frames as defined in FRAME_RATE.'''\n",
        "    vs = cv2.VideoCapture(video_path)\n",
        "    if not vs.isOpened():\n",
        "        raise Exception(f'Unable to open file {video_path}')\n",
        "\n",
        "    total_frames = vs.get(cv2.CAP_PROP_FRAME_COUNT)\n",
        "    frame_time = 0\n",
        "    frame_count = 0\n",
        "    print(\"Total frames:\", total_frames)\n",
        "    print(\"FRAME_RATE\", FRAME_RATE)\n",
        "\n",
        "    while True:\n",
        "        vs.set(cv2.CAP_PROP_POS_MSEC, frame_time * 1000)\n",
        "        frame_time += 1 / FRAME_RATE\n",
        "        _, frame = vs.read()\n",
        "        if frame is None:\n",
        "            break\n",
        "        frame_count += 1\n",
        "        yield frame_count, frame_time, frame\n",
        "\n",
        "    vs.release()\n",
        "\n",
        "\n",
        "\n",
        "def clear_database():\n",
        "    '''Clear the database'''\n",
        "    conn = sqlite3.connect('images.db')\n",
        "    c = conn.cursor()\n",
        "    c.execute('DELETE FROM images')\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "def insert_image_into_db(filename, image):\n",
        "    '''Insert image into the database'''\n",
        "    conn = sqlite3.connect('images.db')\n",
        "    c = conn.cursor()\n",
        "\n",
        "    # Insert image data into the table\n",
        "    c.execute(\"INSERT INTO images (filename, image) VALUES (?, ?)\", (filename, image))\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "def detect_unique_screenshots(video_path, interval=8):\n",
        "    '''Function to detect unique screenshots and display them'''\n",
        "    # Initialize fgbg a Background object with Parameters\n",
        "    fgbg = cv2.createBackgroundSubtractorMOG2(history=FGBG_HISTORY, varThreshold=VAR_THRESHOLD, detectShadows=DETECT_SHADOWS)\n",
        "\n",
        "    captured = False\n",
        "    start_time = time.time()\n",
        "    (W, H) = (None, None)\n",
        "\n",
        "    screenshots_count = 0\n",
        "    for frame_count, frame_time, frame in get_frames(video_path):\n",
        "        orig = frame.copy()  # clone the original frame (so we can save it later),\n",
        "        frame = imutils.resize(frame, width=600)  # resize the frame\n",
        "        mask = fgbg.apply(frame)  # apply the background subtractor\n",
        "\n",
        "        # if the width and height are empty, grab the spatial dimensions\n",
        "        if W is None or H is None:\n",
        "            (H, W) = mask.shape[:2]\n",
        "\n",
        "        # compute the percentage of the mask that is \"foreground\"\n",
        "        p_diff = (cv2.countNonZero(mask) / float(W * H)) * 100\n",
        "\n",
        "        # Capture screenshot at defined interval (every 4 seconds)\n",
        "        if frame_time % interval < 1 / FRAME_RATE:\n",
        "            screenshots_count += 1\n",
        "            # Display the frame using cv2_imshow\n",
        "            cv2_imshow(orig)\n",
        "            # Save the frame to the database\n",
        "            _, img_encoded = cv2.imencode('.png', orig)\n",
        "            insert_image_into_db(f\"screenshot_{screenshots_count}.png\", img_encoded.tobytes())\n",
        "            print(f\"Screenshot {screenshots_count} inserted into database\")\n",
        "\n",
        "    print(f'{screenshots_count} screenshots Captured!')\n",
        "    print(f'Time taken {time.time() - start_time}s')\n",
        "    return\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    video_urls = input(\"Please enter the YouTube video URLs (comma-separated): \").split(',')\n",
        "\n",
        "    for video_url in video_urls:\n",
        "        video_url = video_url.strip()\n",
        "        if video_url:\n",
        "            print('Processing video_url:', video_url)\n",
        "\n",
        "            # Clear the database for new video\n",
        "            clear_database()\n",
        "\n",
        "            # Download the video from the URL\n",
        "            video_path = download_youtube_video(video_url)\n",
        "\n",
        "            if video_path:\n",
        "                # Process the video to detect and display unique screenshots\n",
        "                detect_unique_screenshots(video_path, interval=3)\n",
        "            else:\n",
        "                print(\"Failed to download video.\")\n",
        "        else:\n",
        "            print(\"Invalid URL entered.\")\n"
      ],
      "metadata": {
        "id": "T_WucnskU4e4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "import numpy as np\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import pytesseract\n",
        "\n",
        "def fetch_images_from_db():\n",
        "    '''Fetch images from the database'''\n",
        "    conn = sqlite3.connect('images.db')\n",
        "    c = conn.cursor()\n",
        "\n",
        "    # Fetch all image records from the table\n",
        "    c.execute(\"SELECT id, filename, image FROM images\")\n",
        "    images = c.fetchall()\n",
        "    conn.close()\n",
        "\n",
        "    return images\n",
        "\n",
        "def display_remaining_images():\n",
        "    '''Fetch and display remaining images from the database and extract text'''\n",
        "    remaining_images = fetch_images_from_db()\n",
        "    print(f\"Remaining images in database: {len(remaining_images)}\")\n",
        "\n",
        "    for i, (id, filename, image_data) in enumerate(remaining_images, 1):\n",
        "        np_image = np.frombuffer(image_data, dtype=np.uint8)\n",
        "        img = cv2.imdecode(np_image, cv2.IMREAD_COLOR)\n",
        "        cv2_imshow(img)\n",
        "\n",
        "        # Extract text from image using Tesseract\n",
        "        extracted_text = pytesseract.image_to_string(img)\n",
        "        print(f\"Slide-{i}: Text from {filename}\\n{extracted_text}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    display_remaining_images()\n"
      ],
      "metadata": {
        "id": "IwO7kkPhU69Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install openai\n"
      ],
      "metadata": {
        "id": "UKmb_XxHU9oY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "import numpy as np\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import pytesseract\n",
        "\n",
        "# Set the Tesseract command path (if necessary)\n",
        "pytesseract.pytesseract.tesseract_cmd = r'/usr/bin/tesseract'\n",
        "\n",
        "def fetch_images_from_db():\n",
        "    '''Fetch images from the database'''\n",
        "    conn = sqlite3.connect('images.db')\n",
        "    c = conn.cursor()\n",
        "    c.execute(\"SELECT id, filename, image FROM images ORDER BY id ASC\")\n",
        "    images = c.fetchall()\n",
        "    conn.close()\n",
        "    return images\n",
        "\n",
        "def delete_image_from_db(image_id):\n",
        "    '''Delete an image from the database using its ID'''\n",
        "    conn = sqlite3.connect('images.db')\n",
        "    c = conn.cursor()\n",
        "    c.execute(\"DELETE FROM images WHERE id=?\", (image_id,))\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "    print(f\"Deleted image ID: {image_id}\")\n",
        "\n",
        "def normalize_text(text):\n",
        "    '''Normalize text by removing extra spaces, newlines, and other non-visible characters'''\n",
        "    return ' '.join(text.split())\n",
        "\n",
        "def extract_and_filter_images():\n",
        "    '''Extract text from images and delete duplicates based on the sliding window technique'''\n",
        "    images_data = fetch_images_from_db()\n",
        "    if not images_data:\n",
        "        print(\"No images to process.\")\n",
        "        return\n",
        "\n",
        "    previous_text = None  # Text of the last unique image\n",
        "\n",
        "    # Process each image\n",
        "    for i, (image_id, filename, image_data) in enumerate(images_data, 1):\n",
        "        np_image = np.frombuffer(image_data, dtype=np.uint8)\n",
        "        img = cv2.imdecode(np_image, cv2.IMREAD_COLOR)\n",
        "        cv2_imshow(img)  # Display each image\n",
        "\n",
        "        extracted_text = normalize_text(pytesseract.image_to_string(img).strip())\n",
        "        print(f\"Slide-{i}: Text from {filename}\\n{extracted_text}\")\n",
        "\n",
        "        # Check for duplicates\n",
        "        if extracted_text:\n",
        "            if previous_text is not None and extracted_text == previous_text:\n",
        "                delete_image_from_db(image_id)\n",
        "            else:\n",
        "                previous_text = extracted_text  # Update the text of the last unique image\n",
        "        else:\n",
        "            print(f\"No text extracted from image ID: {image_id}, skipping deletion check.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    extract_and_filter_images()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E4dxmR-yVAr6",
        "outputId": "99b29cf0-38a6-4f13-bb23-fa724d9a95da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No images to process.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "import numpy as np\n",
        "\n",
        "def fetch_images_from_db():\n",
        "    '''Fetch images from the database'''\n",
        "    conn = sqlite3.connect('images.db')\n",
        "    c = conn.cursor()\n",
        "\n",
        "    # Fetch all image records from the table\n",
        "    c.execute(\"SELECT id, filename, image FROM images\")\n",
        "    images = c.fetchall()\n",
        "    conn.close()\n",
        "\n",
        "    return images\n",
        "\n",
        "images = fetch_images_from_db()\n"
      ],
      "metadata": {
        "id": "VERh9FrfVEMr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.models import resnet50\n",
        "from PIL import Image\n",
        "import io\n",
        "\n",
        "# Load a pre-trained ResNet model\n",
        "model = resnet50(pretrained=True)\n",
        "model.eval()\n",
        "\n",
        "# Define a transformation to resize the image and convert it to tensor\n",
        "preprocess = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "def get_embedding(image_bytes):\n",
        "    image = Image.open(io.BytesIO(image_bytes))\n",
        "    image = preprocess(image).unsqueeze(0)  # Add batch dimension\n",
        "    with torch.no_grad():\n",
        "        embedding = model(image)\n",
        "    return embedding.squeeze().numpy()  # Remove batch dimension\n",
        "\n",
        "# Convert all images to embeddings\n",
        "image_embeddings = [(id, filename, get_embedding(image)) for id, filename, image in images]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N9G-f8GVVGie",
        "outputId": "adedbd8b-7d9b-4e38-911b-d3bc60dc66f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 194MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def find_duplicates(embeddings, threshold=0.96):\n",
        "    ids_to_remove = set()\n",
        "    embeddings_list = [embedding for _, _, embedding in embeddings]\n",
        "\n",
        "    # Reshape embeddings to 2D array\n",
        "    embeddings_list = np.array(embeddings_list).reshape(len(embeddings_list), -1)\n",
        "\n",
        "    # Calculate cosine similarities between embeddings\n",
        "    similarities = cosine_similarity(embeddings_list)\n",
        "    for i in range(len(similarities)):\n",
        "        for j in range(i + 1, len(similarities)):\n",
        "            if similarities[i][j] > threshold:\n",
        "                ids_to_remove.add(embeddings[i][0])\n",
        "                break\n",
        "\n",
        "    return ids_to_remove\n",
        "\n",
        "ids_to_remove = find_duplicates(image_embeddings)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "LK--O3deVGeh",
        "outputId": "473828cf-6345-4b7c-fd47-e8577addadbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "cannot reshape array of size 0 into shape (0,newaxis)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-9144df577a2d>\u001b[0m in \u001b[0;36m<cell line: 20>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mids_to_remove\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mids_to_remove\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_duplicates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_embeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-19-9144df577a2d>\u001b[0m in \u001b[0;36mfind_duplicates\u001b[0;34m(embeddings, threshold)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# Reshape embeddings to 2D array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0membeddings_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# Calculate cosine similarities between embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 0 into shape (0,newaxis)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_duplicates_from_db(ids_to_remove):\n",
        "    conn = sqlite3.connect('images.db')\n",
        "    c = conn.cursor()\n",
        "\n",
        "    # Delete duplicates\n",
        "    c.executemany('DELETE FROM images WHERE id=?', [(id,) for id in ids_to_remove])\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "remove_duplicates_from_db(ids_to_remove)\n"
      ],
      "metadata": {
        "id": "GMB-n7K4VLBa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Removed {len(ids_to_remove)} duplicate images from the database.\")"
      ],
      "metadata": {
        "id": "pb9fmPQDVNgA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "import numpy as np\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "def fetch_images_from_db():\n",
        "    '''Fetch images from the database'''\n",
        "    conn = sqlite3.connect('images.db')\n",
        "    c = conn.cursor()\n",
        "\n",
        "    # Fetch all image records from the table\n",
        "    c.execute(\"SELECT id, filename, image FROM images\")\n",
        "    images = c.fetchall()\n",
        "    conn.close()\n",
        "\n",
        "    return images\n",
        "\n",
        "def display_remaining_images():\n",
        "    '''Fetch and display remaining images from the database'''\n",
        "    remaining_images = fetch_images_from_db()\n",
        "    print(f\"Remaining images in database: {len(remaining_images)}\")\n",
        "\n",
        "    for id, filename, image_data in remaining_images:\n",
        "        np_image = np.frombuffer(image_data, dtype=np.uint8)\n",
        "        img = cv2.imdecode(np_image, cv2.IMREAD_COLOR)\n",
        "        cv2_imshow(img)\n",
        "        print(f\"Displayed {filename}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    display_remaining_images()\n"
      ],
      "metadata": {
        "id": "UsHYCzTRVP0U"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}